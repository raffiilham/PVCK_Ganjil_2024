{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuw2oywuMhsta1ptDUp4oO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raffiilham/PVCK_Ganjil_2024/blob/main/ml_jobsheet2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Praktikum 1**\n",
        "Pra Pengolahan Data - Data Terstruktur"
      ],
      "metadata": {
        "id": "6HCymt8TtrgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 1 - Load Data**"
      ],
      "metadata": {
        "id": "noDzYq1IsJi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() # upload dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "HJbUynVCrspn",
        "outputId": "f7c676fb-8a7e-4af7-ae0d-98b10e48577d"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ff6f06b5-5345-4948-bbd4-2da85f28e1a8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ff6f06b5-5345-4948-bbd4-2da85f28e1a8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DKZiz4u3t1eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "df = pd.read_csv(io.BytesIO(uploaded['Titanic-Dataset.csv'])) # load dataset"
      ],
      "metadata": {
        "id": "PLg_ylh5r0Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tampilkan data teratas dengan perintah df.head()"
      ],
      "metadata": {
        "id": "CRVZwsUgstJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "6BXgV1K_sEWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 2 - Pengecekan Data**"
      ],
      "metadata": {
        "id": "pIMUmZ7IsbI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "QnMNCvGHsVIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya, untuk lebih mengetahui jumlah data yang hilang untuk setiap kolom, gunakan perintah,"
      ],
      "metadata": {
        "id": "a8FmahjAsmDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "g3BmeE6xseiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 3 - Imputasi**"
      ],
      "metadata": {
        "id": "mSbOybz5s0Gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada langkah ini kita akan melakukan imputasi terdapat data yang hilang pada \"Age\", \"Cabin\", dan \"Embarked\".\n",
        "\n",
        "Strategi yang akan kita gunakan adalah,\n",
        "\n",
        "\"Age\" --> Dikarenakan \"Age\" adalah data nominal, maka kita akan menggunakan strategi mean.\n",
        "\n",
        "\"Cabin\" --> \"Cabin\" merupakan informasi terkait dengan nomor kabin penumpang. Disini kita akan berasumsi bahwa, seluruh penumpang yang tidak memiliki nomor kabin, merupakan penumpang yang tinggal di dek-dek kapal. Sehingga kita akan mensubtitusi data yang hilang dengan informasi \"DECK\".\n",
        "\n",
        "\"Embarked\" --> \"Embarked\" merupakan informasi lokasi embarkasi penumpang. Hanya ada 2 data yang hilang disini. Dikarenakan data merupakan data nominal, maka kita dapat menggunakan modus (mode) untuk mensubtitusi data yang hilang."
      ],
      "metadata": {
        "id": "Bj7Faxyws5yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Age - mean\n",
        "df['Age'].fillna(value=df['Age'].mean(), inplace=True)\n",
        "\n",
        "# Cabin - \"DECK\"\n",
        "df['Cabin'].fillna(value=\"DECK\", inplace=True)\n",
        "\n",
        "# Embarked - modus\n",
        "df['Embarked'].fillna(value=df['Embarked'].mode, inplace=True)"
      ],
      "metadata": {
        "id": "8T1cHyv1s2yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 4 - Validasi Hasil**"
      ],
      "metadata": {
        "id": "wv3FkKnPs8Vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lakukan pengecekan kembali dengan df.info(). Selanjutnya, kita juga dapat memastikan kembali apakah nilai yang disikan sudah benar dengan melakukan pencekan data secara langsung. Hasil dari proses imputasi adalah sebagai berikut,"
      ],
      "metadata": {
        "id": "EjoVVZVAtNyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "nF8TqTZHtX8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "8eFLoGDUtbga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Praktikum 2**\n",
        "Seleksi Fitur, Encoding, dan Standarisasi"
      ],
      "metadata": {
        "id": "J0AJHa9lt-Q0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 0 - Load Library**"
      ],
      "metadata": {
        "id": "smYNWQeIuRJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "7wpSKVowuOOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 1 - Load Data**"
      ],
      "metadata": {
        "id": "xm16jhjBubgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() # upload dataset"
      ],
      "metadata": {
        "id": "5atRHHGwurlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dpath = 'Titanic-Dataset-fixed.csv'\n",
        "df = pd.read_csv(dpath)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "cLS4g32Iuga1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 2 - Slice Data**"
      ],
      "metadata": {
        "id": "JjrU9E55vArB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['Survived', 'Pclass', 'Age', 'Sex', 'Cabin']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "bPZj3QWbu86T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 3 - Encoding**\n",
        "Strategi yang kita gunakan adalah Label Encoding. Label Encoding serupa dengan Ordinal Encoding, bedanya hanya pada proses pengurutan. Label Encoding tidak mengurutkan data terlebih dahulu."
      ],
      "metadata": {
        "id": "iGG49d7qvIEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder() # membuat objek dari LabelEncoder\n",
        "df['Sex'] = le.fit_transform(df['Sex']) # proses encoding\n",
        "df['Cabin'] = le.fit_transform(df['Cabin']) # proses encoding"
      ],
      "metadata": {
        "id": "boidCaqVvPAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 4 - Verifikasi Hasil**"
      ],
      "metadata": {
        "id": "C6YuchaMvZs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "1EUebRSgvcYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 5 - Standarisasi**"
      ],
      "metadata": {
        "id": "U4mWsmJRvfa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "std = StandardScaler()\n",
        "df['Age'] = std.fit_transform(df[['Age']])"
      ],
      "metadata": {
        "id": "s1BJzQXwv4WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 6 - Verifikasi Hasil Standarisasi**"
      ],
      "metadata": {
        "id": "OE-3dplCv6XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "2_ImDglUv8Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Praktikum 3**\n",
        "Spliting Data"
      ],
      "metadata": {
        "id": "WVaVCBkxwBCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Random Split**\n",
        "### **Langkah 1 - Load Data**"
      ],
      "metadata": {
        "id": "oYLtUNFvwMUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() # upload dataset"
      ],
      "metadata": {
        "id": "yftDSwzTwhd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Titanic-Dataset-selected.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6ywXFA3FwJTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 2 - Split Data**"
      ],
      "metadata": {
        "id": "OKlaYaG9wn7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data training dan dan lainnya\n",
        "# data lainnya, akan kita split lagi menjadi validasi dan testing.\n",
        "# Rasio yang akan kita gunakan adalah 8:1:1\n",
        "df_train, df_unseen = train_test_split(df, test_size=0.2, random_state=0)\n",
        "\n",
        "# Split lagi antara validasi dan testing\n",
        "df_val, df_test = train_test_split(df_unseen, test_size=0.5, random_state=0)\n",
        "\n",
        "# Cek masing-masing ukuran data\n",
        "\n",
        "print(f'Jumlah data asli: {df.shape[0]}')\n",
        "print(f'Jumlah data train: {df_train.shape[0]}')\n",
        "print(f'Jumlah data val: {df_val.shape[0]}')\n",
        "print(f'Jumlah data test: {df_test.shape[0]}')\n",
        "\n",
        "# Cek rasio tiap label\n",
        "print('=========')\n",
        "print(f'Jumlah label data asli:\\n{df.Survived.value_counts()}')\n",
        "print(f'Jumlah label data train:\\n{df_train.Survived.value_counts()}')\n",
        "print(f'Jumlah label data val:\\n{df_val.Survived.value_counts()}')\n",
        "print(f'Jumlah label data test:\\n{df_test.Survived.value_counts()}')"
      ],
      "metadata": {
        "id": "uzHhBqDVwrlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cross Validation 1**\n",
        "Pada praktikum ini, kita akan membuat data latih dan data uji saja dengan menggunakan metode cross validation.\n",
        "\n",
        "### **Langkah 1 - Load Data**"
      ],
      "metadata": {
        "id": "62l41jS9w1kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df3 = pd.read_csv('Titanic-Dataset-selected.csv')\n",
        "df3.head()"
      ],
      "metadata": {
        "id": "JTa8yyofw5Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 2 - Split Data**"
      ],
      "metadata": {
        "id": "GsKEUVoow9np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementasi k-fold cross validation (random) dengan training dan testing saja\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# inisiasi obyek kfold\n",
        "kf = KFold(n_splits=4)\n",
        "print(f'Jumlah fold: {kf.get_n_splits()}')\n",
        "print(f'Obyek KFold: {kf}')\n",
        "\n",
        "# Lakukan splitting dengan KFold\n",
        "kf_split = kf.split(df3)\n",
        "print(f'Jumlah data df: {df.shape[0]}')\n",
        "\n",
        "# cek index data tiap fold\n",
        "for train_index, test_index in kf_split:\n",
        "    print(f'Index train: {train_index} | Index test: {test_index}')"
      ],
      "metadata": {
        "id": "W4KjVGbOxAKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cross Validation 2**\n",
        "### **Langkah 1 - Load Data**"
      ],
      "metadata": {
        "id": "p7hX9SBoxGAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df4 = pd.read_csv('Titanic-Dataset-selected.csv')\n",
        "df4.head()"
      ],
      "metadata": {
        "id": "ZK5P6gvGxMj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 2 - Split Data**"
      ],
      "metadata": {
        "id": "w2wt7XGSxQvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementasi k-fold cross validation (random) dengan training, validation, dan testing data\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "# Split dulu antara data training dan testing dengan train_test_split\n",
        "# Rasio 8:2 untuk training dan testing\n",
        "df4_train, df4_test = train_test_split(df4, test_size=0.2, random_state=0)\n",
        "\n",
        "# inisiasi obyek kfold\n",
        "kf2 = KFold(n_splits=4)\n",
        "print(f'Jumlah fold: {kf2.get_n_splits()}')\n",
        "print(f'Obyek KFold: {kf2}')\n",
        "\n",
        "# Lakukan splitting dengan KFold untuk data df_training\n",
        "# Dengan acara ini, kita masih memiliki data testing untuk keperluan pengujian model\n",
        "# namun tetap dapat melakukan evaluasi dengan menggunakan data validasi\n",
        "kf2_split = kf2.split(df_train)\n",
        "print(f'Jumlah data df_train: {df4_train.shape[0]}')\n",
        "\n",
        "# cek index data tiap fold\n",
        "for train_index, test_index in kf2_split:\n",
        "    print(f'Index train: {train_index} | Index test: {test_index}')"
      ],
      "metadata": {
        "id": "hYOKOHG8xSg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Praktikum 4**\n",
        "Ekstraksi Fitur Data Tidak Terstruktur\n",
        "### **Langkah 0 - Instal Library**"
      ],
      "metadata": {
        "id": "7hN5eek_ySVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow"
      ],
      "metadata": {
        "id": "pzl7lbypybCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 1 - Load Image**"
      ],
      "metadata": {
        "id": "mtsA4saCyg54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() # upload dataset"
      ],
      "metadata": {
        "id": "n59GK8yXzSrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "img = Image.open('Lenna.png')\n",
        "img.show() # tampilkan gambar\n",
        "display(img) # metode alternatif tampilkan gambar"
      ],
      "metadata": {
        "id": "XkymZ0MFyk8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 2 - Ekstrak Fitur**"
      ],
      "metadata": {
        "id": "yKMw1aiSzlaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ekstrak setiap channel red, green, blue\n",
        "r, g, b = img.split()\n",
        "\n",
        "# Cek panjang ukuran channel red\n",
        "print(len(r.histogram()))\n",
        "\n",
        "# Cetak fitur histogram pada channel red\n",
        "print(r.histogram())"
      ],
      "metadata": {
        "id": "lA25NWr1zzms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tugas Praktikum**\n",
        "### **Deskripsi Tugas**\n",
        "Pada tugas pratikum ini Anda akan menggunakan data \"Wisconsin Breast Cancer\". Data tersebut terdiri dari 569 data yang digunakan untuk mendiagnonis jenis kanker Malignant (M) dan Benign (B). Tugas Anda adalah,\n",
        "\n",
        "1. Pisahkan antara variabel yang dapat digunakan dan variabel yang tidak dapat digunakan.\n",
        "\n",
        "2. Lakukan proses encoding pada kolom \"diagnosis\".\n",
        "\n",
        "3. Lakukan proses standarisasi pada semua kolom yang memiliki nilai numerik.\n",
        "\n",
        "4. Lakukan proses stratified split data untuk membuat data latih dan data uji dengan rasio 80:20."
      ],
      "metadata": {
        "id": "lh2NLmvdz-Nq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Langkah 1 - Load image**"
      ],
      "metadata": {
        "id": "QfV1Pzgz0d8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() # upload dataset"
      ],
      "metadata": {
        "id": "m_3TSgzlz84s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}